\input{preambule}
\usepackage{geometry}
\geometry{hmargin=1.2cm,vmargin=1.5cm}

\begin{document}


\title{An $ARD_1$-type model based on two dependent Wiener processes
\author{Margaux {\sc Leroy}$^{1,2}$, Christophe {\sc B\'erenguer}$^{1}$, Laurent {\sc Doyen}$^{2}$, Olivier {\sc Gaudoin}$^{2}$\\
1. Univ. Grenoble Alpes, CNRS, Grenoble INP, GIPSA-lab, 38000 Grenoble, France\\
2. Univ. Grenoble Alpes, CNRS, Grenoble INP, LJK, 38000 Grenoble, France
}}

\maketitle

\begin{abstract}

\end{abstract}

{\it Keywords}: Degradation modeling, Imperfect maintenance, Statistical inference, Observation scheme, First hitting time.


%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

[revue de la littérature ]\\
Industrial or technological devices can be subject to degradation during their lifetime because of the intrinsic wear, environmental cause or operating conditions. In order to prevent degradation and extend their lifetime, maintenance actions are performed.  
Inspired by the degradation model defined in \cite{mercier_stochastic_2019}, an $ARD_1$-type model based on one underlying Wiener process with drift is proposed to model degradation including imperfect maintenance action \cite{leroy_statistical_2022}.

In this article, different observations schemes are considered. In the first observation scheme,  degradation levels are observed just before and just after every maintenance action. For instance, This situation can happen  in practice (\cite{zhao_accelerated_2021}) where maintenance actions are performed on  electrical distribution devices to avoid corrosion. The maintenance times (i.e. the times where maintenance actions are performed) are considered to be instantaneous. At these times jumps can be observed on the degradation trajectory simulated with the $ARD_1$ Wiener-based degradation model. Using this model implies that the value of a jump is proportional to the degradation accumulated since the last maintenance action. In this first observation scheme, the jumps are deterministic conditionally to the previous observations. This scheme is not realistic as, in practice, the values of the jumps and the accumulated degradation since the last maintenance barely happen to be  proportional. 

\noindent In order to avoid this issue, two underlying Wiener processes with drift are considered. In \cite{mercier_bivariate_2012}, railway track's wear depends on  two dependent deterioration indicators that measure the geometry track. These indicators are modeled by bivariate Gamma processes. With this method, better predictions of the maintenance times are provided rather than using the  univariate Gamma process.

\noindent Let $\{X_a(t)\}_{t \geq0 }$ and $\{X_b(t)\}_{t \geq0 }$ be two dependent Wiener processes with drift.

\noindent Let $X_a(t)$ (resp. $X_b(t)$) be a degradation level at time $t$ of a non-maintained system. Thus, $ X_a(t)= \mu_a t + \sigma_a B_a(t)$ and $X_b(t)= \mu_b t + \sigma_b B_b(t)$ where $B_a$ and $B_b$ are standard Brownian motions. $\mu_a$ and $\mu_b$ are the drift parameters, and $\sigma_a$ and $\sigma_b$ are the variance parameters. 
Then, we assume that the system's degradation consists of the degradation of two dependent components (modeled by  $X_a(t)$ and $X_b(t)$), and that the maintenance has only an effect on the second component (see thereafter). 

\noindent This model is built following the next assumptions,

\begin{itemize}
\item
 $\begin{pmatrix}
X_a \\
X_b
\end{pmatrix} $
is a bivariate Wiener process so that $\begin{pmatrix}
X_a \\
X_b
\end{pmatrix} $ =  $\begin{pmatrix}
\mu_a \\
\mu_b
\end{pmatrix} $ t +  $\begin{pmatrix}
\sigma_a & c\\
c & \sigma_b
\end{pmatrix} $  $\begin{pmatrix}
B_a(t) \\
B_b(t)
\end{pmatrix} $ 
\item The degradation is modeled by the sum of the two processes $X_a$ and $X_b$ 
\item The maintenance action has an effect only on component $X_b$. This effect is $ARD_1$ type \cite{mercier_stochastic_2019}
\item Between  two maintenance actions, the system is degrading  as a non-maintained system.
\end{itemize}
 




$\begin{pmatrix}
X_a(t)\\
X_b(t)
\end{pmatrix}$
$\sim \mathcal{N}\left( ^t(\mu_a \ \ \mu_b )\ t,\   \Sigma_{ab} \ t \right)$ where $ \Sigma_{ab}=$
$\begin{pmatrix}
\sigma_a^2 \  &  c_{ab}  \\
 c_{ab}  & \sigma_b^2
\end{pmatrix}$, $ c_{ab} t= Cov \left(X_a(t),\ 
X_b(t)\right)$
where $ \Sigma_{ab} $ is  positive definite i.e. $\ |c_{ab}| \leq \sigma_a \sigma_b$.\\

\noindent The coefficient correlation between $X_{a}(t)$ and $X_{b}(t)$ is $Corr(X_{a}(t),X_{b}(t)) \ =\frac{Cov(X_{a}(t),X_{b}(t))}{\sigma_a \sigma_b\ t}=\frac{c_{ab}}{\sigma_a\sigma_b}=r_{ab}$ , $ r_{ab}\in [-1,1]$. Therefore, the correlation coefficient does not depend on time. 

\label{section:intro}

\section{Maintenance effect on the model}

This section presents a new degradation model with maintenance actions. The underlying degradation processes are Wiener processes and the maintenance effect is $ARD_1$-type \cite{mercier_stochastic_2019}. 


\noindent Let $Y(t)$ be the degradation level at time $t$ of a maintained system. Let $(\tau_1,\tau_2,...,\tau_k)$ be the maintenance times, i.e. times where a maintenance is performed (maintenance actions are considered to be instantaneous). \\


\noindent Let $Y(\tau_j^-)$ (resp. $Y(\tau_j^+)$) be the degradation level just before (resp. after) the $j^{th}$ maintenance at time $\tau_j$. Let $t_{j,i}$ be the $i^{th}$ observation time after the $j^{th}$ maintenance action.  

\noindent Before the first maintenance action, the system is degrading according to the Wiener processes $X_a(t)$ and $X_b(t)$. We assume that the first degradation level equals to 0 at time 0 so that
\begin{align*}
Y(0)&=0\\
\forall\ t \in [0,\tau_1[,\ Y(t)&=X_a(t)+X_b(t)\\
Y(\tau_1^-)&=X_a(\tau_1)+X_b(\tau_1)
\end{align*}

\noindent At time $\tau_1$, a maintenance of the $ARD_1$ type is performed : the maintenance effect is to reduce the degradation level of a quantity proportional to the amount of degradation of $X_b(t)$ accumulated since the last maintenance \cite{mercier_stochastic_2019}. In this paper, a time during which a maintenance action is performed is assumed to be negligible and the maintenance actions are thus instantaneous.
\begin{align*}
Y(\tau_1^+)&=Y(\tau_1^-)-\rho \left(X_b(\tau_1)- X_b(0)\right) \\
&=X_a(\tau_1)+X_b(\tau_1)-\rho X_b(\tau_1)\\
\forall\ t \in [\tau_1,\tau_2[,\ Y(t)&=Y(\tau_1^+)+X_a(t)+X_b(t)-X_a(\tau_1)-X_b(\tau_1)\\
&=X_a(t)+X_b(t)-\rho X_b(\tau_1)\\
Y(\tau_2^-)&=X_a(\tau_2)+X_b(\tau_2)-\rho X_b(\tau_1)
\end{align*}

The maintenance effect remains the same  $ \forall j \in \{1,...,k\}$ so that by recurrence ,
\begin{align*}
Y(\tau_j^+)&=Y(\tau_j^-)-\rho \left(X_b(\tau_j)- X_b(\tau_{j-1})\right) \\
&=X_a(\tau_j)+X_b(\tau_j)-\rho X_b(\tau_j)\\
\forall\ t \in [\tau_j,\tau_{j+1}[,\ Y(t)&=Y(\tau_j^+)+X_a(t)+X_b(t)-X_a(\tau_j)-X_b(\tau_j)\\
&=X_a(t)+X_b(t)-\rho X_b(\tau_j)\\
Y(\tau_{j+1}^-)&=X_a(\tau_{j+1})+X_b(\tau_{j+1})-\rho X_b(\tau_j)
\end{align*}


Every time a maintenance is performed, degradation jumps are observed at maintenance times. Let $Z_j^{(1)}$ be the observed jump around the $j^{th}$ maintenance action.
\begin{align*}
Y(\tau_j^+)&=X_a(\tau_j)+X_b(\tau_j)-\rho X_b(\tau_j)\\
Y(\tau_j^-)&=X_a(\tau_{j})+X_b(\tau_j)-\rho X_b(\tau_{j-1})\\
Z_j^{(1)}&=Y(\tau_j^+)-Y(\tau_j^-)=-\rho\ \left(X_b(\tau_j)- X_b(\tau_{j-1})\right)
\end{align*}

\noindent To simplify the next calculations, another parameterization of the model is given.
Let us define $X^{(1)}(t)= X_a(t)+X_b(t)$ and $X^{(2)}(t)=X_b(t)$ so that 
\begin{align}
\forall t\in [\tau_j,\tau_{j+1}[,\ \ Y(t)=X^{(1)}(t)-\rho\ X^{(2)}(\tau_j)
\label{eq:Yt}
\end{align}



\begin{align*}
Cov \left(X^{(1)}(t),\ X^{(2)}(t)\right)&= Cov( X_a(t)+X_b(t)\ ,\ X_b(t))\\
&=Cov( X_a(t),\ X_b(t))+ \mathbb{V}[X_b(t)]\\
&=  c_{ab}\ t+\sigma_b^2\ t \\
\mathbb{V}ar[X^{(1)}(t)]&= \mathbb{V}ar[X_a(t)]+\mathbb{V}ar[X_b(t)]+ 2\ Cov (X_a(t),X_b(t))\\
 &=\sigma_a^2\ t\ +\sigma_b^2\ t\ +2\  c_{ab} \ t\\
 \mathbb{V}ar[X^{(2)}(t)]&=\sigma^2_b\ t 
\end{align*}


\noindent $\begin{pmatrix}
X^{(1)}(t)\\
X^{(2)}(t)
\end{pmatrix}$ is a bivariate Wiener process so that 
$\begin{pmatrix}
X^{(1)}(t)\\
X^{(2)}(t)
\end{pmatrix}$
$\sim \mathcal{N}\left( \begin{pmatrix}
\mu_a\ +\mu_b\  \\ \mu_b \ 
\end{pmatrix}\  t\ , \ \Sigma\ t \right)$ 

\noindent Where $\Sigma= \begin{pmatrix}
\sigma_a^2\ +\sigma_b^2\ +2\  c_{ab}  &  c_{ab}+\sigma_b^2 \\
 c_{ab}+ \sigma_b^2 & \sigma_b^2
\end{pmatrix}$\\

\noindent The coefficient correlation between $X^{(1)}(t)$ and $X^{(2)}(t)$ is $Corr(X^{(1)}(t),X^{(2)}(t)) \ =\frac{Cov(X^{(1)}(t),X^{(2)}(t))}{\sigma_1 \sigma_2\ t}=\frac{c_{12}}{\sigma_1\sigma_2}=r_{12}$ , $ r_{12}\in [-1,1]$. Therefore, the correlation coefficient $r_{12}$ does not depend on time. \\



%\begin{align*}
%-\sigma_a \sigma_b \leq c_{ab} &\leq \sigma_a \sigma_b \\
%\Leftrightarrow  c_{ab}^2 &\leq  \sigma_a^2 \sigma_b^2 \\
%\Leftrightarrow c_{ab}^2 + \sigma_b^4+ 2 c_{ab}\sigma_b^2  &\leq \sigma_a^2 \sigma_b^2+\sigma_b^4+2 c_{ab}\sigma_b^2 \\
%\Leftrightarrow  (c_{ab}+\sigma_b^2)^2 & \leq \sigma_b^2 (\sigma_a^2+\sigma_b^2+2c_{ab}) \\
%\text{Then, } -1  &\leq \frac{c_{ab}+\sigma_b^2}{\sigma_b \sqrt{\sigma_a^2+\sigma_b^2+2c_{ab})}} \leq 1 
%\end{align*}
%
%Thus,  $r\in [-1,1]$.\\


To simplify writings, let us write 
\begin{align*}
\forall \ m \in\{1,2\} \ \ \Delta X^{(m)}_j &= X^{(m)}(\tau_j)- X^{(m)}(\tau_{j-1})\\
\Delta X^{(m)}_{j,i} &= X^{(m)}(t_{j,i})- X^{(m)}(t_{j,i-1})\\
\mu_1&=\mu_a +\mu_b  &  \mu_a&=\mu_1-\mu_2\\
\mu_2&= \mu_b  & \mu_b& =\mu_2\\
\sigma_1^2&=\sigma_a^2+\sigma_b^2+2\ c_{ab}  &\sigma_a^2&= \sigma_1^2+\sigma_2^2-2c_{12}\\
\sigma_2^2&=\sigma_b^2  & \sigma_b^2&=\sigma_2^2 \\
c_{12}&= c_{ab} + \sigma_b^2  & c_{ab} &=c_{12}-\sigma_2^2\\
r_{12}&=\frac{r_{ab} \sigma_a +\sigma_b}{\sqrt{\sigma_a^2+\sigma_b^2+2\ r_{ab} \sigma_a \sigma_b}} & r_{ab} &=\frac{ r_{12} \sigma_1   -\sigma_2}{\sqrt{\sigma_1^2+\sigma_2^2-2 \ r_{12} \sigma_1 \sigma_2}}
\end{align*}


Indeed, we have 
\begin{align*}
r_{ab}&=\frac{c_{ab}}{\sigma_a \sigma_b}
=\frac{c_{12}-\sigma_2^2}{\sigma_2 \sqrt{\sigma_1^2+\sigma_2^2-2 c_{12}}}
=\frac{r_{12}\sigma_1-\sigma_2}{\sqrt{\sigma_1^2+\sigma_2^2-2 \ r_{12} \sigma_1 \sigma_2}}
\end{align*}
and both parameterizations are equivalent.


%The application $\ \begin{matrix}
%\mathbb{R}\ $x$\ \mathbb{R}\ $x$\ \mathbb{R}^+_*\ $x$\ \mathbb{R}^+_*\ $x$\ \mathbb{R}\\
%(\mu_1,\ \mu_2,\ \sigma_1^2,\ \sigma_2^2,\  c) 
%\end{matrix} $
%$\longmapsto$ 
%$\begin{matrix}
%\mathbb{R}\ $x$ \ \mathbb{R}\ $x$\ \mathbb{R}^+_* $x$\ \mathbb{R}^+_* $x$\ \mathbb{R}\\
%(\mu_1-\mu_2,\ \mu_2,\ \sigma_1^2+\sigma_2^2-2 c,\ \sigma_2^2,\ c-\sigma_2^2)
%\end{matrix}\ $ is bijective and 

%\begin{align*}
%|c_{ab}| &\leq \sigma_a\sigma_b \\
%\Leftrightarrow - \sigma_2 \sqrt{\sigma_1^2+\sigma^2_2-2 c }&\leq c-\sigma_2^2 \leq  \sigma_2 \sqrt{\sigma_1^2+\sigma^2_2-2 c }\\
%\Leftrightarrow 0 \leq (c-\sigma_2^2)^2 & \leq \sigma_2^2 (\sigma_1^2+\sigma^2_2-2 c)\\
% \Leftrightarrow -\sigma_1 \sigma_2 &\leq c \leq \sigma_1 \sigma_2 
%\end{align*}

For all $j \in \{1,...,k\}$, a maintenance is performed at time $\tau_j$. Let $Z_j$ be the degradation jump at $\tau_j$. As written before, the maintenance has only an effect on $X_2(t)$ so that $Z_j$ only depends on $X_2(t)$ :

\begin{align}
Z_j=Y(\tau_j^+)-Y(\tau_j^-)=-\rho\ \left(X^{(2)}(\tau_j)- X^{(2)}(\tau_{j-1})\right)
\label{eq:mainteff}
\end{align}



In some specific cases, one can notice that :

\begin{itemize}

\item The initial Wiener-based $ARD_1$ model defined in \cite{leroy_statistical_2022} is equivalent to this bivariate Wiener-based model when  $\forall t \ X_a(t)=0$, i.e. $\mu_a=\sigma_a=c_{ab}=0$. In this case, $r_{12}=1$, $\mu_1=\mu_2$, $\sigma_1=\sigma_2$ and $X^{(1)}=X^{(2)}$.

\item When the  processes $X_a$ and $X_b$ are independent, $r_{ab}=0$, $r_{12}=\frac{\sigma_b}{\sqrt{\sigma_a^2+\sigma_b^2}}$ so that $X_1$ and $X_2$ remain dependent and are positively correlated.

\item When the processes $X_1$ and $X_2$ are independent, $r_{12}=0$  and $r_{ab}=-\frac{\sigma_2}{\sqrt{\sigma_1^2+\sigma_2^2}}$ so that $X_a$ and $X_b$ remain dependent and are negatively correlated.

\item $r_{ab}=1\Leftrightarrow\ r_{12}=1$
\item $r_{ab}=-1\Rightarrow\ r_{12}=\{-1,1\}$
\item $r_{12}=-1\Leftrightarrow\ r_{ab}=-1$
\item $r_{12}=1\Rightarrow\ r_{ab}=\{-1,1\}$

\end{itemize}



In \Cref{traj}, the observed degradation process $Y$ is represented by the underlying processes $X_a$ and $\ X_b$ (on the left) and $X_1$ an $X_2$ (on the right). These degradation trajectories have been simulated using the following parameters :  $\mu_a=4$, $\mu_b=2$, $\sigma_a^2=10$, $\sigma_b^2=7$, $\rho=0.7$, $r_{ab}=0.8$ which is equivalent to $\mu_1=6$, $\mu_2=2$, $\sigma_1^2=30.39$, $\sigma_2^2=7$, $\rho=0.7$, $r_{12}=0.94$.

In this trajectory, four maintenance actions are periodically performed at times $\{3,6,9,12\}$. The underlying processes are simulated using consecutive degradation increments (each one following normal distributions) on time increments equal to $0.001$. In the first parameterization, the degradation increments (in black) between maintenance actions evolve as the addition of the two underlying processes increments on the same time intervals. In the second parameterization, these increments evolve as the first underlying process increments.\\ 




%\begin{figure}[h!]
%\begin{multicols}{2}
%\includegraphics[scale=0.8]{figures/trajab_n20.png} \\
%\includegraphics[scale=0.8]{figures/traj12_n20.png} 
%\end{multicols}
%\caption{Degradation trajectories (in black) defined by the two underlying Wiener processes (in pink and blue) and according to their different writings : using $(X_a,\ X_b)$  in the left figure and $(X^{(1)} ,X^{(2)})$ in the right figure.}
%\label{traj}
%\end{figure}

%In \Cref{traj2}, the correlation between $X_a$ and $X_b$ clearly appears on the processes trajectories. Here again, the two same trajectories are represented using the different writings of the underlying processes ($X_a,\ X_b$) and ($X_1,\ X_2$). These trajectories include  the next parameters :  $\mu_a=4$, $\mu_b=3$, $\sigma_a^2=15$, $\sigma_b^2=10$, $\rho=0.6$, $r_{ab}=0.8$ and $\mu_1=7$, $\mu_2=3$, $\sigma_1^2=55.6$, $\sigma_2^2=10$, and  $r=0.94$. \\

\begin{figure}[h!]
\begin{multicols}{2}
\includegraphics[scale=0.9]{figures/trajab.png} \\
\includegraphics[scale=0.9]{figures/traj12.png} 
\end{multicols}
\caption{Degradation trajectories (in black) defined by the two underlying Wiener processes and according to their different writings : using $(X_a,\ X_b)$  (in green and blue) in the left figure and $(X^{(1)} ,X^{(2)})$ (in red and blue) in the right figure.}
\label{traj}
\end{figure}

Let us write $\Delta \tau_j=\tau_j-\tau_{j-1}$. The distributions of the degradation increments  $\forall t, s \in  [\tau_j,\tau_{j+1}[$, the degradation level  $\forall t \in [\tau_j,\tau_{j+1}[$ and the jumps at the maintenance times are Gaussian distributed so that : 

\begin{itemize}
\item   $ \displaystyle Y(t)-Y(s)\sim  \mathcal{N}\left(\mu_1 (t-s)\ ,\ \sigma_1^2 (t-s)\right)$
\item   $\displaystyle  Y(t)\sim \mathcal{N}\left(\mu_1t-\rho \mu_2 \tau_j\ ,\  \sigma_1^2 t +\rho^2 \sigma_2^2 \tau_j -2 \rho c \tau_j \right)$
\item  $Z_j\sim \mathcal{N}\left(-\rho \mu_2 \Delta \tau_j\ ,\  \rho^2 \sigma_2^2 \Delta \tau_j\right)$ 
\end{itemize}


\section{First hitting time}

Let us assume that the system fails as soon as the degradation level exceeds a given threshold.
The first time that exceeds this critical degradation level is called the first hitting time. 

\begin{figure}[h!]
\begin{multicols}{2}
\centering

\includegraphics[width=9.2 cm, height= 5 cm]{figures/rul.emp3.png}
\caption{Distribution of the first passage time under given parameters}
\label{rul1} 

\columnbreak

\includegraphics[width=9.2 cm, height= 5 cm]{figures/deg.rul.png}
\caption{One example of a simulated degradation trajectory under the same parameters used in \Cref{rul1}}
\label{trajrul} 
\end{multicols}
\end{figure}





In \Cref{rul1}, 5000 first hitting times are simulated. Each one is simulated from a trajectory using the following parameters : $\mu_1=40$, $\mu_2=30$, $\sigma_1^2=10$, $\sigma_2^2=7$, $\rho=0.8$, $r_{12}=0.7$, the time period equals to $0.001$, a maintenance is performed after 50 time increments, thus the maintenance period equals to $0.05$ and a given critical threshold $s$ is set to $2.6$. The density is obtained using the kernel density estimation with a Gaussian kernel. In the right figure, every rectangle represents the same number of hitting times.

%If the observed jumps at maintenance times are big enough (which can happen when  $\mu_2$ and $\rho$ are big enough, and for a sufficient time between two successive maintenance actions), 

Under these parameters, it appears that the first passage time is multimodal distributed. 
In \Cref{rul1}, the peaks on the empirical density are linked to the maintenance times.

% The more $X^{(1)}$ and $X^{(2)}$ are correlated, the more time's increments between the gaps are equivalent to the maintenance period $\Delta \tau$.

%Let $h$ be the critic degradation threshold, i.e. the degradation level of the first passage time.

%Let $T_h$ be the first passage time. $\mathbb{P}(T_h \in [\tau_j,\tau_{j+1}[)=\pi_j$ and $\sum\limits_{j=0}^{\infty} \pi_j=1$. 

%Let $y_0$ and $t_0$ be respectively the first degradation level and the first degradation time.

%In \cite{kahle_degradation_2016}, the first passage time of a non-maintained system concerning a Wiener process with drift is Inverse Gaussian distributed. According to this bivariate Wiener-based $ARD_1$ model, on every interval $[\tau_j, \tau_{j+1}[$ the first passage time is Inverse Gaussian distributed with $\displaystyle \mu=\frac{h-y(\tau_j^+)}{\mu_1}$ the mean parameter and $\displaystyle \lambda=\frac{(h-y(\tau_j^+))^2}{\sigma_1^2}$ the shape parameter.

%Let $g$ be the density of the first passage time $T_h$.

%Assumption on the density's writing of $T_h$ : 

%$g(t,\Phi)=\sum\limits_{j=0}^{+\infty} \pi_j f_{IG(\mu_j,\lambda_j)}(t,\Theta_j)$  
%where $\Phi=(\pi_0,\pi_1,\pi_2...,\mu_0,\mu_1,\mu_2,...\lambda_0,\lambda_1,\lambda_2...)$ and $f_{IG(\mu_j,\lambda_j)}(t,\Theta_j)$ is the density of the inverse Gaussian distribution with parameters $\mu_j$ and $\lambda_j$.

\section{Statistical Inference}
In the following section, statistical inference is studied according to different observation schemes. Each scheme leads to a different writing of the likelihood and then to different estimations of the parameters.

\subsection{First observation scheme}
In this observation scheme, the degradation levels are observed just before and just after every maintenance actions.
\subsubsection{Likelihood}

Let $L_1(\mu_1,\mu_2,\sigma_1^2,\sigma_2^2,\rho,r_{12})$ be the likelihood under the first observation scheme (the degradation levels just before and just after each maintenance action are observed).
Let $f_X$ be the density of $X$ and $\mathcal{O}^1_{\tau_j^-}$ the set of observations before time $\tau_j$. $k$ is the number of maintenance actions, $n_j$ is the number of observed degradation levels between two maintenance actions on $]\tau_j,\tau_{j+1}[$. $\Delta Y_{j,i}=Y(t_{j,i})-Y(t_{j,i-1})$ is the $i^{th}$ degradation increment after the $j^{th}$ maintenance. Since the degradation levels are observed just before and just after every maintenance action, then, under this observation scheme, $Z_j^{(1)}=Y(\tau_j^+)-Y(\tau_j^-)$ is observed $\forall j \in \{1,...,k\}$. Let $\Delta t_{j,i}$ be the observed time increments so that $\Delta t_{j,i}=t_{j,i}-t_{j,i-1}$. let $\Theta$ be the set of all the parameters, so that $\Theta=(\mu_1, \mu_2, \sigma_1^2, \sigma_2^2,\rho, r_{12})$


\noindent The likelihood is written as :

\begin{align}
\displaystyle L_1(\Theta)= \prod \limits_{j=0}^k \prod \limits_{i=1}^{n_{j}+1} \ f_{\Delta Y_{j,i}}\ (\Delta y_{j,i})\prod \limits_{j=1}^k \ f_{Z_j^{(1)} \mid \mathcal{O}^1_{\tau_j^-}}(z_j) 
\end{align}


\begin{align}
\Delta Y_{j,i}=\Delta X^{(1)}_{j,i}\sim \mathcal{N}\left(\mu_1 \Delta t_{j,i},\ \sigma_1^2 \Delta t_{j,i}\right)
\label{eq:inc}
\end{align}


\noindent Let us write  $\Delta X^{(2)}_j=X^{(2)}(\tau_j)-X^{(2)}(\tau_{j-1})=\sum \limits_{i=1}^{n_{j-1}+1} \Delta X^{(2)}_{j-1,i}\ $ and $\ \Delta X^{(1)}_j=X^{(1)}(\tau_j)-X^{(1)}(\tau_{j-1})=\sum \limits_{i=1}^{n_{j-1}+1} \Delta X^{(1)}_{j-1,i}$. According to (\ref{eq:mainteff}), $Z_j^{(1)}=-\rho \Delta X^{(2)}_j$. Unlike \cite{leroy_statistical_2022}, the jumps do not depend on the previous observations. In order to write $f_{Z_j^{(1)} \mid \mathcal{O}^1_{\tau_j^-}}(z_j)$ the density of the observed jumps conditionally to the previous observations, and using the Lemma 1, it is necessary to know the distribution of the vector $\begin{pmatrix}
 \Delta X^{(2)}_j\ \\
   \Delta X^{(1)}_j
\end{pmatrix}$.  As the the processes $X^{(1)}_j$ and $X^{(2)}_j$ are dependent on the same time interval $\Delta \tau_j$, writing the distribution of the jumps conditionally to the previous increments is equivalent to write this distribution only conditionally to the observed increments on $\Delta \tau_j$.\\


\setlength{\fboxsep}{7mm}% définir l'écart
\setlength{\fboxrule}{0.3 mm} % définir l'épaisseur du trait

\fbox{
\begin{minipage}[c]{15 cm}
\noindent Lemma 1 \cite{kozt_continuous_2000} \\
\noindent Conditional Gaussian distributions :\\
Let us consider a Gaussian vector such as 
 
 $\begin{pmatrix} 
 U \\
 V
\end{pmatrix} \sim \mathcal{N}(\mu,\Sigma)$, $\mu$ and $\Sigma$ are partitioned as follows \\
$\mu=\begin{pmatrix} \mu_U \\ \mu_V \end{pmatrix}$ and 
$\Sigma=\begin{pmatrix} \Sigma_{U} &\Sigma_{UV} \\ \Sigma_{VU} &\Sigma_{V}\end{pmatrix}$\\
\noindent Then, the distribution of $U$ conditional on $V=v$ is a multivariate normal
\begin{align}
  &(U \mid V=v)\sim \mathcal{N}(\tilde{\mu},\tilde \Sigma) \text{ where }\nonumber \\ 
  &{\bf \tilde{\mu}=\mu_u+\Sigma_{UV}\Sigma_{V}^{-1}(v-\mu_V)} \text{ and covariate  matrix } {\bf \tilde \Sigma=\Sigma_{U}-\Sigma_{UV}\Sigma_{V}^{-1}\Sigma_{VU}}
  \label{formule}
  \end{align}

 \end{minipage}
}


\begin{align}
 \begin{pmatrix}
 \ \Delta X^{(2)}_j\ \\
   \Delta X^{(1)}_j
 \end{pmatrix} \sim  \mathcal{N}\bigg(\Delta \tau_j\begin{pmatrix}
  \mu_2  \\ \mu_1
 \end{pmatrix}\ ,\ \Delta \tau_j \begin{pmatrix}  \sigma_2^2   &c\\\   c\ &  \sigma_1^2\ \end{pmatrix} \bigg)
\label{eq:saut1}
\end{align}

%$M_1^{-1}=\frac{1}{ \Delta \tau_j^2 (\sigma_1^2\sigma_2^2-c^2)}\begin{pmatrix}\sigma_1^2 \Delta \tau_j & -\ c \ \Delta \tau_j \\
%- \ c \ \Delta \tau_j & 
% \sigma_2^2 \Delta \tau_j
% \end{pmatrix}$\\
 

\begin{align}
Z_j^{(1)} \big | \mathcal{O}^1_{\tau_j^-}&= \left(-\rho \ \Delta X^{(2)}_j \right)\ \bigg | \bigg( \ \Delta X^{(1)}_j=y(\tau_j^-)- y(\tau_{j-1}^+) \bigg) \text{ \hspace{1 cm} Where \hspace{1 cm} } \Delta y_j= y(\tau_j^-)- y(\tau_{j-1}^+)
\end{align}


\noindent According to the Lemme 1 (\ref{formule}) and (\ref{eq:saut1}), let us consider $U=\Delta X^{(2)}_j$, $V=\Delta X^{(1)}_j$, $\mu_U=\mu_2 \Delta \tau_j$, $\mu_V=\mu_1 \Delta \tau_j$, $\Sigma_U=\sigma_2^2 \Delta \tau_j$, $\Sigma_V=\sigma_1^2 \Delta \tau_j$, and $\Sigma_{UV}=c \Delta \tau_j$  so that :

\begin{align}
Z_j^{(1)} \mid \mathcal{O}^1_{\tau_j^-}&\sim \mathcal{N}\left( - \rho\big( \mu_2 \Delta \tau_j + \frac{c_{12}}{\sigma_1^2} \ (\Delta y_{j}-\mu_1 \Delta \tau_j)\big)\ , \  \rho^2 \Delta \tau_j\big(\sigma_2^2 -\frac{ c_{12}^2 }{\sigma_1^2}\big)\right)\nonumber \\
&\sim \mathcal{N}\left( - \rho\big( \mu_2 \Delta \tau_j + r_{12}\frac{ \sigma_2}{\sigma_1} \ (\Delta y_{j}-\mu_1 \Delta \tau_j)\big)\ , \  \rho^2 \Delta \tau_j\ \sigma_2^2\big( 1-r_{12}^2\big)\right)
\end{align}

\noindent Then, the log-likelihood is written as follows :

\begin{align}
\ln L(\Theta)=&-\frac{1}{2} \Bigg(\sum \limits_{j=0}^k \sum_{i=1}^{n_j+1} \ln(2\pi\sigma_1^2\Delta t_{j,i})+ \frac{(\Delta y_{j,i}-\mu_1 \Delta t_{j,i})^2}{\sigma_1^2 \Delta t_{j,i}} \nonumber \\
&+ \sum_{j=1}^{k} \ln(2\pi \rho^2\Delta \tau_j \sigma_2^2(1-r_{12}^2))+\frac{(z_j^{(1)}+\rho \mu_2 \Delta \tau_j+\rho r_{12}\frac{\sigma_2}{\sigma_1}(\Delta y_{j}-\mu_1 \Delta \tau_j))^2}{\rho^2 \Delta \tau_j \sigma_2^2 (1-r_{12}^2)}\Bigg)
\label{eq:likelihood}
\end{align}

%\noindent  This Log likelihood writing shows a significant identifiability problem in the model. For instance, one can notice that $L(\mu_1,\mu_2,\sigma_1^2, \sigma_2^2, \rho ,r_{12})=L(\mu_1,\tilde \mu_2,\sigma_1^2, \tilde \sigma_2^2, \tilde \rho ,r_{12})$ where $\tilde \mu_2=\frac{1}{2}\mu_2$, $\tilde \sigma_2 =\frac{1}{2} \sigma_2$ and $ \tilde \rho =2\ \rho$.


Furthermore, one can easily notice an identifiability problem in the model: let us note $\tilde \rho= 2 \rho$ and $\tilde X^{(2)}=\frac{1}{2}X^{(2)}$, then using $\tilde \rho$ and $\tilde X^{(2)}$ in (\ref{eq:Yt}), we have $Y(t)=X^{(1)}(t)$ and thus cannot estimate the parameters properly.  The same problem is encountered by using the initial parameterization (using $X_a$ and $X_b$ processes).

\noindent In order to avoid this issue, constraints have to be given on the parameters. Then, two assumptions (among others) can be provided. In the one hand, let us assume that $\mu_a=0$ (i.e. $\mu_1=\mu_2$). This way, the degradation model is defined by the $X_b$ process and a disruption $X_a$. In the other hand, let us assume that the maintenance efficiency parameter is known so that $\rho=1$. In that case, maintenance actions are perfect. In practice, while modeling a component's degradation, this situation happens whenever the maintenance action consist in replacing the component.

\subsubsection{ Estimations }

In order to see the influence of the parameters values, the number of maintenance actions and observations on the estimation's quality, several situations are considered and compared to each other.

\paragraph{1$^{st}$ case : $\mu_1=\mu_2$}
~~\\

\begin{table} [!h]
\caption{Summary of the different features used for the simulations}
\centering
\label{table:para}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
Situation & $\mu_1$ & $\mu_2$ &  $\sigma_1^2$  &  $\sigma_2^2$ & $\rho$ & $r_{12}$ & $n_j$ & $k$ & $n$  & Maintenance period\\
\hline
1& 5&5&10&7&0.5&0.7&2&4&20&3\\
2&5&5&10&7&0.5&0.7&0&9&20&1 \\
3&5&5&10&7&0.5&0.7&8&1&20&9 \\
4&5&5&10&7&0.5&0.7&2&49&200&3 \\
5&5&5&10&7&0.2&0.7&2&4&20&3 \\
6&5&5&10&7&0.8&0.7&2&4&20&3 \\
7&5&5&13&6&0.5&0.1&2&4&20&3 \\
8&5&5&10&20&0.5&0.7&2&4&20&3 \\



\hline
\end{tabular}
\end{table}


\begin{figure}[h!]
\centering
\begin{multicols}{3}
\includegraphics[width=6 cm, height= 5 cm]{figures/estim/estim_mu_S18.png} 
\includegraphics[width=6 cm, height= 5 cm]{figures/estim/estim_rho_S18.png} \\
\columnbreak

\includegraphics[width=6 cm, height= 5 cm]{figures/estim/estim_sigma21_S18.png} 
\includegraphics[width=6 cm, height= 5 cm]{figures/estim/estim_r_S18.png} \\
\columnbreak

\includegraphics[width=6 cm, height= 5 cm]{figures/estim/estim_sigma22_S18.png} \\


\end{multicols}
\caption{Estimations of the five parameters based on 5000 simulated degradation trajectories and following different situations (see \Cref{table:para})}
\label{estim_para}
\end{figure}

In \Cref{estim_para}, in each situation, 5000 degradation trajectories are simulated according to different values of the parameters and different numbers of observations and maintenance actions (see \Cref{table:para}). The five model's parameters are estimated with the Nelder-Mead method. 
\noindent Different techniques are employed to initialize the parameters for this method.
\begin{itemize}
\item initialization of $\mu_1$ , $\mu_2$ and $\sigma_1^2$ : 
Let us consider a simulated degradation trajectory without taking the jumps into account (i.e. only the degradation increments between the maintenance actions are considered). In that case, the trajectory's likelihood only depends on  $\mu_1$ and $\sigma_1^2$ so that $L(\mu_1,\sigma_1^2)=\prod \limits_j\prod \limits_i f_{\Delta Y_{j,i}}(\Delta y_{j,i})$ where $\Delta Y_{j,i}$ follow a normal distribution (\ref{eq:inc}). These two parameters are then initialized using the maximum likelihood method. Let $\mu_1^{(0)}$, $\mu_2^{(0)}$ and ${\sigma_1^2}^{(0)}$  be the values used for the algorithm's initialization.  $N=\sum\limits_{j=0}^k n_j$ so that we have,\\
 $\displaystyle \mu_1^{(0)}=\frac{\sum\limits_{j=0}^k\sum\limits_{i=1}^{n_j+1} \Delta y_{j,i}}{\sum\limits_{j=0}^k\sum\limits_{i=1}^{n_j+1} \Delta t_{j,i}}$ and $\displaystyle {\sigma_1^2}^{(0)}=\frac{1}{N+k+1}\sum\limits_{j=0}^k\sum\limits_{i=1}^{n_j+1}\frac{(\Delta y_{j,i}-\mu_1^{(0)} \Delta t_{j,i})^2}{ \Delta t_{j,i}}$.
 
\noindent Since $\mu_1=\mu_2$, the initial value of $\mu_2$ is set at $\mu_1^{(0)}$ so that $\mu_1^{(0)}=\mu_2^{(0)}$.

\item initialization of $\rho$ :  Since $Z_j\sim \mathcal{N}\left(-\rho \mu_2 \Delta \tau_j\ ,\  \rho^2 \sigma_2^2 \Delta \tau_j\right)$, then $\mathbb{E}[Z_j]=-\rho \mu_2 \Delta \tau_j=-\rho \mu_1 \Delta \tau_j$. Let us write $\bar{Z_k}=\frac{1}{k}\sum\limits_{j=0}^k Z_j$ and $\rho^{(0)}$ an estimated value of $\rho$. So $\displaystyle \rho^{(0)}=\frac{\bar{Z_k}}{-\mu_1^{(0)}\Delta \tau_j}$. Since the maintenance times are periodically given, $\forall j  \in \{1,...,k\}\ \Delta \tau_j$ is constant.

\item initialization of $\sigma^2_2$ : 
\noindent Let us now only consider the jumps in a degradation trajectory (i.e. only the observed jumps at the maintenance times). Then, the jumps $(Z_1^{(1)},Z_2^{(1)},...,Z_k^{(1)})$ are independent and the jumps likelihood is written as $L( \sigma_2^2)=\prod\limits_{j=1}^k f_{Z_j^{(1)}}(z_j^{(1)})$.  Let ${\sigma_2^2}^{(0)}$ be an estimated value of $\sigma_2^2$. ${\sigma_2^2}^{(0)}$ can be obtained by using the maximum likelihood based on the jumps likelihood. Then,  ${\sigma_2^2}^{(0)}=\frac{1}{k} \sum \limits_{j=1}^k \frac{(z_j^{(1)}+\rho^{(0)}\mu_2^{(0)}\Delta \tau_j)^2}{{\rho^{(0)}}^2\Delta \tau_j}$ .

\item initialization of $r_{12}$ :  Let $r_{12}^{(0)}$ be an estimation of the correlation parameter $r_{12}$. We have, $\frac{Z^{(1)}_j}{-\rho}=\Delta X^{(2)}_j$ and $\Delta  Y_j=\Delta X^{(1)}_j$. Then, $r_{12}^{(0)}=\frac{Cov \big(\frac{Z^{(1)}_j}{-\rho}\ ,\ \Delta  Y_j \big)}{\sigma_1^{(0)}\sigma_2^{(0)} \Delta \tau_j}$ can be used as an initialization of the parameter $r_{12}$. If only one jump is observed on a degradation trajectory, then $r_{12}^{(0)}$ is  arbitrarily chosen.  If the estimation of $r_{12}$ is greater than $1$, then $r_{12}^{(0)}$ is set at $1$. If the estimation of $r_{12}$ is lower than $-1$, then $r_{12}^{(0)}$ is set at $-1$.

\end{itemize}



\noindent In the first three situations, each trajectory is represented by twenty observations simulated with the same values of the five parameters. Only the number of maintenance actions (and thus the number of observations between two successive maintenance actions) changes from one situation to another. In the first situation, $4$ maintenance actions are performed, in the second situation, $9$ maintenance actions are performed and only $1$ maintenance action appears in the third situation.

\noindent The estimations of the drift $\mu_1$ (or $\mu_2$) are rather good as the bias and the dispersion of the estimators are very small.
% This parameter appears in the writing of the degradation increments densities  between the maintenance actions as well as in the writing of the jumps densities conditionally to the previous (cf. \ref{eq:likelihood}) . These last densities  depend on all the five parameters which may disrupt a little bit the estimations of $\mu_1$ and $\sigma_1^2$.
In these first  situations, it seems that the estimations dispersion for $\mu_1$ and $\sigma^2_1$ is greater as the number of maintenance action increases. In the second situation, only one degradation increment is observed between two successive maintenance actions which may disrupt a little bit the estimations of $\mu_1$ and $\sigma_1^2$.  Yet, a very few number of maintenance actions can provide a  slight bias to the drift estimations.

\noindent The three other parameters $\sigma_2^2$, $\rho$ and $r_{12}$ only appear in the jumps densities conditionally to the previous observations. Here, for these three parameters, the more maintenance actions are performed the better the estimations are. This is particularly obvious for the estimations of the correlation coefficient $r_{12}$, when only one maintenance action is given, $r_{12}$ cannot be estimated properly. 

\noindent The maintenance efficiency parameter $\rho$ is always well estimated as biases and dispersion of the box plots are tiny. Indeed, this parameter appears in the writing of the jumps density but also in the trend of the increments between those jumps. 

\noindent Furthermore, the estimations of $r_{12}$ and $\sigma_2^2$ are bound to each other. When the estimations of $r_{12}$ are overestimated and the bias is positive, then the estimations of $\sigma_2^2$ are negatively biased. As a matter of fact, $r_{12}=\frac{c_{12}}{\sigma_1\sigma2}$, thus these results are not surprising. One could expect the same estimations behavior for $\sigma_1^2$, but, as this parameter is also represented between the maintenance actions (and no only at the maintenance times), the estimations of $\sigma_1^2$ are less dependent on the correlation coefficient estimations.

\noindent In situation 4, 200 degradation levels are observed on each simulated trajectory. The maintenance period remains the same as in situation 1, then 49 maintenance actions are performed. In this asymptotic situation, the estimations of all the parameters are satisfying as the dispersion is strongly reduced and no bias are visible on the box plots.

\noindent In situations 1, 5 and 6, only the value of $\rho$ the maintenance efficiency parameter varies  from $0.2$ to $0.8$. The value of this parameter does not seem to have any influence on the other parameters estimations. However, it seems that the more the value of $\rho$ is close to $0$ the better the estimations of $\rho$ are. Indeed, the dispersion of the estimations of $\rho$ is smaller when $\rho$ is closer to $0$.


\noindent In situation 7, the correlation coefficient is close to $0$. It seems that when the underlying  degradation processes are  not very correlated, it affects the estimations of $\sigma_2^1$ as the bias and dispersion are slightly bigger than in the other situations. Let us note that it does not impact the estimations of $\sigma_2^2$. Moreover, a low value of the correlation coefficient affects significantly the estimations of $r_{12}$ as the estimations dispersion are way more extended.



\noindent In situation 8, the value of $\sigma_2^2$ is greater than $\sigma_1^1$. In this case, the initial underlying processes $X_a$ and $X_b$ are negatively correlated. It seems that the value of $\sigma_2^2$ does not affect the other parameters estimations but affects badly its own estimation. Bias and dispersion are much bigger when a high value of $\sigma_2^2$ is considered.



%\begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu1_n200.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma21_n200.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu2_n200.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma22_n200.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_rho_n200.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_corr_n200.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0.5$, $r=0.7$, $n=200$, $n_j=2$,$k=49$}
%\label{estim_n200}
%\end{figure}
%
%
%
%
%
%In \Cref{estim_n200}, the same 5000  trajectories are simulated (as in \Cref{estim_n20}). Each trajectory includes 200 observations and 49 maintenance actions. The six model's parameters are estimated with the Nelder-Mead method. In this asymptotic case, the parameter estimations are  more precise as the bias and the variances are way smaller on the box plots. 
%
%When comparing the figures  \ref{estim_n20} and \ref{estim_n200} with the figures \ref{estim_n20_r0} and \ref{estim_n200_r0}, one can notice that the bias of $\hat r$ are bigger when $r=0$.
%
%
%\begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu1_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma21_r0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu2_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma22_r0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_rho_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_corr0.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0.5$, $r=0$, $n=20$, $n_j=2$, $k=4$}
%\label{estim_n20_r0}
%\end{figure}
%
%\begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu1_n200_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma21_n200_r0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu2_n200_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma22_n200_r0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_rho_n200_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_corr0_n200.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0.5$, $r=0$, $n=200$, $n_j=2$, $k=49$}
%\label{estim_n200_r0}
%\end{figure}
%
%\begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu1_nj0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma21_nj0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu2_nj0.png} \\
%
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma22_nj0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_rho_nj0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_corr_nj0.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0.5$, $r=0.7$, $n=20$, $n_j=0$, $k=9$}
%\label{estim_nj0}
%\end{figure}
%
%
%\begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu1_n20_tp9.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma21_n20_tp9.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu2_n20_tp9.png} \\
%
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma22_n20_tp9.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_rho_n20_tp9.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_corr_n20_tp9.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0.5$, $r=0.7$, $n=20$, $n_j=8$, $k=1$}
%\label{estim_n20_tp9}
%\end{figure}
%
%In \Cref{estim_n20_tp9}, one maintenance action is performed. In this case, the likelihood includes only the density of one jump which is not enough to estimate the parameters $\mu_2$, $\sigma_2$, $\rho$ and $r$ properly.
%
%
%In the writing of the likelihood $\mu_2$ only appears in the jumps densities and is always multiplied by $\rho$. In the previous situations, every time  $\mu_2$ is overrated, $\rho$ is underrated.
%
%

\paragraph{2$^{nd}$ case : $\rho=1$}
~~\\

The estimators are now computed with a given maintenance efficiency parameter ($\rho=1$). 


\begin{table} [!h]
\caption{Summary of the different features used for the simulations}
\centering
\label{table:para_rho1}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline
Situation & $\mu_1$ & $\mu_2$ &  $\sigma_1^2$  &  $\sigma_2^2$  & $r_{12}$ & $n_j$ & $k$ & $n$  & Maintenance period\\
\hline
1& 10&5&10&7&0.7&2&4&20&3\\
2&10&5&10&7&0.7&0&9&20&1 \\

\hline
\end{tabular}
\end{table}


\begin{figure}[h!]
\centering
\begin{multicols}{3}
\includegraphics[width=6 cm, height= 5 cm]{figures/estim/estim_mu1_r1.png} 
\includegraphics[width=6 cm, height= 5 cm]{figures/estim/estim_sigma22_r1.png} \\
\columnbreak

\includegraphics[width=6 cm, height= 5 cm]{figures/estim/estim_mu2_r1.png} 
\includegraphics[width=6 cm, height= 5 cm]{figures/estim/estim_r_r1.png} \\
\columnbreak

\includegraphics[width=6 cm, height= 5 cm]{figures/estim/estim_sigma21_r1.png} \\


\end{multicols}
\caption{Estimations of the five parameters based on 5000 simulated degradation trajectories and following different situations (see \Cref{table:para_rho1})}
\label{estim_para_rho1}
\end{figure}


\noindent In \Cref{estim_para_rho1}, the estimations of all the parameters can be compared to the first two situations in \Cref{estim_para}. New values of the drift parameters $\mu_1$ and $\mu_2$ are given and $\rho$ does not need to be estimated anymore.

\noindent Comparing  \Cref{estim_para} and \Cref{estim_para_rho1}, the estimations of all the parameters look very similar. Considering a given maintenance efficiency parameter instead of similar drift values does not seem to have any influence on the estimations. Thus, it is not useful to study this alternative.

\clearpage

\subsection{Second observation scheme}

\begin{figure}[h!]
\centering
\includegraphics[width=8.6 cm, height=5 cm]{figures/plot_cas4_n20.png} 
\caption{A trajectory of the degradation process }
\end{figure}

\subsubsection{Likelihood}

Let $L_2(\Theta)$ be the likelihood defined as follows :\\

\begin{align}
L_2(\Theta)&= \prod \limits_{j=0}^k\  \prod \limits_{i=1+\mathds{1}_{j>0}}^{n_{j}} \ f_{\Delta Y_{j,i}}\ (\Delta y_{j,i})\prod \limits_{j=1}^k \ f_{Z_j^{(2)} \mid \mathcal{O}^2_{t_{j-1,n_{j-1}}}}(z_j) 
\end{align}


%\noindent Where $ \tilde{\mathcal{O}}_{t_{j-1,n_{j-1}}}=\{\Delta y_{0,1},\Delta \{y_{\ell,m}\}_{0\leq \ell \leq j-1, \ 2 \leq m \leq n_{\ell} }\}$ are the observed increments before $t_{j-1,n_{j-1}}$ without the observed jumps. \\
\noindent Where $\mathcal{O}^2_{t_{j-1,n_{j-1}}}=\{\Delta y_{0,1},\Delta \{y_{\ell,m}\}_{0\leq \ell \leq j-1, \ 2 \leq m \leq n_{\ell} },\{z_{\ell}\}_{1 \leq \ell \leq  j-1}\}$ is the set of observations before $ t_{j-1,n_{j-1}}$.\\

\noindent In order to write the density of $\left(Z_j^{(2)} \bigg |  \mathcal{O}^2_{t_{j-1,n_{j-1}}}\right)$, it will be necessary to precise the writing of the vector \\
$\displaystyle \left(Z_j^{(2)},\ \sum\limits_{i=1+\mathds{1}_{j>1}}^{n_{j-1}}\Delta X^{(1)}_{j-1,i},\ Z_{j-1}^4\right)$.\\[0.3 cm]

$\forall j \in \{1,...,k\} :$

\begin{align}
Z_j^{(2)}&=Y(t_{j,1})-Y(t_{j-1,n_{j-1}}) \nonumber\\
&=\Delta X^{(1)}_{j-1,n_{j-1}+1}-\rho\ \Delta X^{(2)}_j + \Delta X^{(1)}_{j,1} \\[0.3 cm]
&=\Delta X^{(1)}_{j-1,n_{j-1}+1} + \Delta X^{(1)}_{j,1}-\rho\ \Delta X^{(2)}_{j-1,n_{j-1}+1}-\rho\ \Delta X^{(2)}_{j-1,1}\mathds{1}_{j>1}-\rho\ \sum\limits_{i=1+\mathds{1}_{j>1}}^{n_{j-1}} \Delta X^{(2)}_{j-1,i} \\
\displaystyle \bigg(Z_j^{(2)} \mid \mathcal{O}^2_{t_{j-1,n_{j-1}}} \bigg )=&\left( Z_j^{(2)}   \Bigg | \Bigg( Z_{j-1}^4=z_{j-1},\ \sum\limits_{i=1+\mathds{1}_{j>1}}^{n_{j-1}}\Delta X^{(1)}_{j-1,i}=\sum\limits_{i=1+\mathds{1}_{j>1}}^{n_{j-1}}\Delta y_{j-1,i}\Bigg) \right) 
\label{eq:saut}
\end{align}

To simplify writings,  let us write $\displaystyle \sum\limits_{i=1+\mathds{1}_{j>1}}^{n_{j-1}}  \Delta t_{j-1,i} = \Delta \tilde t_{j-1}\ $ i.e. the sum of time intervals during which increments of degradation are observed before $\tau_j$, and $\sum\limits_{i=1+\mathds{1}_{j>1}}^{n_{j-1}}  \Delta y_{j-1,i} = \Delta \tilde y_{j-1}$ the sum of all the observed increments before $\tau_j$.\\

\noindent  $\forall j \in \{1,...,k\}$ : 
\begin{align}
\mathbb{E}[Z_j]&= \mu_{Z_j} \ \ \ , \ \ \mathbb{V}ar[Z_j ] =\sigma^2_{Z_j}\ , \ \text{ and }\ \mathbb{E}[\Delta \tilde Y_{j-1}]= \mu_1 \Delta \tilde t_{j-1}\ \ ,\  \ \mathbb{V}[\Delta \tilde Y_{j-1}]=\sigma_1^2  \Delta \tilde t_{j-1} \\
\text{Where, } \mu_{Z_j} =& \Delta t_{j-1,n_{j-1}+1}( \mu_1-\rho \mu_2) + \Delta t_{j,1} \mu_1-\rho \mu_2  \Delta t_{j-1,1} \mathds{1}_{j>1}  -\rho \mu_2 \Delta \tilde t_{j-1} \nonumber \\
&=\mu_1 (\Delta t_{j-1,n_{j-1}+1} + \Delta t_{j,1}  ) -\rho \mu_2 \Delta \tau_j\\
\sigma^2_{Z_j}=& \Delta t_{j-1,n_{j-1}+1}(\sigma_1^2+ \rho^2 \sigma_2^2-2\rho c_{12})+ \sigma_1^2 \Delta t_{j,1} + \rho^2\sigma_2^2 \Delta t_{j-1,1} \mathds{1}_{j>1} +\rho^2 \sigma_2^2 \Delta \tilde t_{j-1} \nonumber \\
&=\sigma_1^2(\Delta t_{j-1,n_{j-1}+1} + \Delta t_{j,1} )+ \rho^2 \sigma_2^2  \Delta \tau_j - 2 \rho \ c_{12} \ \Delta t_{j-1,n_{j-1}+1}
\end{align}
\noindent  $\forall j \in \{2,...,k\}$ : 
\begin{align}
\begin{pmatrix}
Z_j^{(2)}\\ \sum\limits_{i=1+\mathds{1}_{j>1}}^{n_{j-1}}\Delta X^{(1)}_{j-1,i}\\ Z_{j-1}^4
\end{pmatrix} &\sim \mathcal{N}\Bigg( \begin{pmatrix}
\mu_{Z_j} \\ \mu_1 \Delta \tilde t_{j-1} \\ \mu_{Z_{j-1}}
\end{pmatrix}\ , \ \begin{pmatrix}
\sigma^2_{Z_j} & -\rho c_{12} \Delta \tilde t_{j-1} &  -\rho c_{12} \Delta t_{j-1,1}  \\
 -\rho c_{12} \Delta \tilde t_{j-1} & \sigma_1^2 \Delta \tilde t_{j-1} & 0  \\
   -\rho c_{12} \Delta t_{j-1,1} &   0&\sigma^2_{Z_{j-1}}
\end{pmatrix} \Bigg)
\end{align}

With
$\ \ \Sigma_4= \begin{pmatrix}
\sigma_1^2 \Delta \tilde t_{j-1} & 0  \\
  0&\sigma^2_{Z_{j-1}}
\end{pmatrix}$ \hspace{0.6 cm } and \hspace{0.6 cm } $\Sigma_4^{-1}= \begin{pmatrix}
\frac{1}{\sigma_1^2 \Delta \tilde t_{j-1}} & 0  \\
   0&\frac{1}{\sigma^2_{Z_{j-1}}}
\end{pmatrix}$\\


%\textcolor{cyan}{
%\begin{align*}
%|M_4|&=\sigma^2_{Z_j} \sigma^2_{Z_{j-1}}\sigma^2_1 \Delta t_{j-1}^{obs} -\rho^2 c^2( \sigma^2_{Z_{j-1}}\Delta t_{j-1}^{obs^2} +\sigma_1^2  \Delta t_{j-1,1}^2   \Delta t_{j-1}^{obs}\mathds{1}_{j>1} )\\
%M_4^{-1}&=\frac{1}{ |M_4| } \begin{pmatrix}
%\sigma^2_{Z_{j-1}} \sigma_1^2  \Delta t_{j-1}^{obs} & \sigma^2_{Z_{j-1}} \rho c \Delta t_{j-1}^{obs} & \sigma_1^2 \rho c \Delta t_{j-1}^{obs}  \Delta t_{j-1,1}\\
%\sigma^2_{Z_{j-1}} \rho c \Delta t_{j-1}^{obs} & \sigma^2_{Z_{j}}\sigma^2_{Z_{j-1}}+\rho c \Delta t_{j-1,1} & \rho^2 c^2 \Delta t_{j-1}^{obs} \Delta t_{j-1,1}\\
% \sigma_1^2 \rho c \Delta t_{j-1}^{obs}  \Delta t_{j-1,1} &  \rho^2 c^2 \Delta t_{j-1}^{obs} \Delta t_{j-1,1} &  \sigma^2_{Z_{j}}\sigma^2_{Z_{j-1}}-\rho^2 c^2 \Delta t_{j-1}^{obs^2} 
%\end{pmatrix}
%\end{align*}
%}
According to (\ref{formule}), $\forall j \in \{1,...,k\}$, we have:

\begin{align}
\bigg(Z_j^{(2)} \mid \mathcal{O}^2_{t_{j-1,n_{j-1}}} \bigg ) \sim \mathcal{N} \bigg(&\mu_{Z_j} - \frac{\rho\ c_{12} }{\sigma_1^2}\big( \Delta \tilde y_{j-1}-\mu_1 \Delta \tilde t_{j-1}\big)- \frac{\rho\ c_{12}  \Delta t_{j-1,1}\mathds{1}_{j>1} }{\sigma^2_{Z_{j-1}}}\big(z_{j-1}- \mu_{z_{j-1}}\big) , \nonumber\\
&\sigma^2_{Z_j}-\rho^2 c_{12}^2 \bigg(\frac{\Delta \tilde t_{j-1}}{\sigma_1^2}+ \frac{\Delta t_{j-1,1}^2 \mathds{1}_{j>1} }{\sigma^2_{Z_{j-1}}}\bigg)\bigg) \nonumber \\
 \sim \mathcal{N} \bigg(&\mu_{Z_j} - \frac{\rho\ r_{12} \sigma_2 }{\sigma_1}\big( \Delta \tilde y_{j-1}-\mu_1 \Delta \tilde t_{j-1}\big)- \frac{\rho\ r_{12} \sigma_1\sigma_2  \Delta t_{j-1,1}\mathds{1}_{j>1} }{\sigma^2_{Z_{j-1}}}\big(z_{j-1}- \mu_{z_{j-1}}\big) , \nonumber\\
&\sigma^2_{Z_j}-\rho^2 r_{12}^2  \sigma_1^2\sigma_2^2 \bigg(\frac{\Delta \tilde t_{j-1}}{\sigma_1^2}+ \frac{\Delta t_{j-1,1}^2 \mathds{1}_{j>1} }{\sigma^2_{Z_{j-1}}}\bigg)\bigg)
\end{align}

%\noindent When $j=1$, $Z_1$ only depends on the previous increments, $\ \Delta t_{0}^{obs}= \sum \limits_{i=1}^{n_0} \Delta t_{0,i}\ $,   $\ \Delta y^{obs}_0=\sum \limits_{i=1}^{n_0} \Delta X^{(1)}_{0,i}\ $, and :
%
%\begin{align}
%\begin{pmatrix}
%Z_1^4\\ 
%\sum\limits_{i=1}^{n_0} \Delta X^{(1)}_{0,i}
%\end{pmatrix} & \sim \mathcal{N} \Bigg( \begin{pmatrix}
%\mu_{Z_1} \\ \mu_1 \Delta t_{0}^{obs} 
%\end{pmatrix}
%, \ \begin{pmatrix}
%\sigma^2_{Z_1} & -\rho c \Delta t_{0}^{obs}  \\
% -\rho c \Delta t_{0}^{obs} & \sigma_1^2 \Delta t_{0}^{obs}  
%\end{pmatrix}\Bigg) 
%\end{align}
%
%
%
%
%
%\begin{align}
%\bigg(Z_1^4 \mid \mathcal{O}_{t_{0,n_{0}}} \bigg )& \sim \mathcal{N}\left(\mu_{Z_1}-\frac{\rho c }{\sigma^2_{1}}\big(\Delta y^{obs}_0-\mu_1 \Delta t^{obs}_0 \big)\ , \ \sigma^2_{Z_1}-\frac{\rho^2 c^2 \Delta t_0^{obs}}{\sigma_1^2 }\right)
%\end{align}

We can notice that when the observations  $ y(t_{j-1,n_{j-1}})$ and $y(t_{j,1})$ tend to the maintenance time $\tau_j$, the fourth observation scheme is equivalent to the first one,  
 $  \Delta \tilde t_{j-1}=\Delta \tau_j$ and $\big(Z_j^{(2)} \mid \mathcal{O}^2_{t_{j-1,n_{j-1}}} \big )\sim  \big(Z_j^{(1)} \mid \mathcal{O}^1_{\tau_j}\big ) $.\\
 
 
 
 \subsubsection{Estimations}
 
% \begin{table} [!h]
%\caption{Summary of the different features used for the simulations}
%\centering
%\label{table:para}
%\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
%\hline
%Situation & Figure& $\mu_1$ & $\mu_2$ &  $\sigma_1^2$  &  $\sigma_2^2$ & $\rho$ & $r$ & $n_j$ & $k$ & $n$  & Maintenance period\\
%\hline
%1&\Cref{estim_cas4} & 4&3&5&3&0.5&0.7&2&4&11&3\\
%2&\Cref{estim_cas4n200} & 4&3&5&3&0.5&0.7&2&49&101&3 \\
%3&\Cref{estim_cas4_r0_n11} & 4&3&5&3&0.5&0&2&4&11&3\\
%4&\Cref{estim_cas4_r0_n101} & 4&3&5&3&0.5&0&2&49&101&3\\
%5&\Cref{estim_cas4_r0_n501} & 4&3&5&3&0.5&0&2&249&501&3\\
%6&\Cref{estim4_r07_n901_tp19} & 4&3&5&3&0.5&0.7&18&49&901&19\\
%7&\Cref{estim4_r0_n901_tp19} & 4&3&5&3&0.5&0&18&49&901&19\\
%8&\Cref{estim4_rh0_n901_tp19} & 4&3&5&3&0&0.7&18&49&901&19\\
%
%
%\hline
%\end{tabular}
%\end{table}
%
%
%\noindent In \Cref{estim_cas4}, 5000 trajectories are simulated including 19 observations and 8 maintenance actions. 
%
%\noindent In \Cref{estim_cas4n200}, 5000 trajectories are simulated including 201 observations and 49 maintenance actions. 
%
%
%
%\noindent Between \Cref{estim_cas4}  and \Cref{estim_cas4_r0_n11}, only the value of $r$ the correlation coefficient changes. Let us notice that in those specific cases, very few degradation levels are observed. When $r=0.7$, the estimations of $\mu_1$, $\mu_2$, $\rho$ and $\sigma^2_2$ are rather good as the bias is small compared to $\sigma_1^2$ and $r$. However, the estimators of $r$ are overestimated and mainly close to 1. On the other hand, when $r=0$, the likelihood's writing is simplified and $ \big(Z_j^{(2)} \mid \mathcal{O}_{t_{j-1,n_{j-1}}} \big )\sim \mathcal{N} \big(\mu_{Z_j} \ , \ \sigma^2_{Z_j}\big)$. In this case, the lack of observations leads to a bad estimation's quality of $r$. To have an idea of the impact of the  correlation coefficient's value, let us have  a look on \Cref{estim_cas4n200} ($r=0.7$) and \Cref{estim_cas4_r0_n101} ($r=0$). This time, in both situations, $49$ maintenance actions and $101$ observations are considered. Here, when $r=0.7$ the estimations are way better : the dispersion of the estimators is tinier and the bias disappears compared to \Cref{estim_cas4} and \Cref{estim_cas4_r0_n11}, except for $\hat r$ which is a little bit overestimated. When $r=0$ the dispersion of the estimators is wider and the bias of $\hat r$ remains overrated.
%
%Besides, when the maintenance efficiency parameter equals to 0, the likelihood does not rely on the second process anymore. So $L_1$ does not depend on $\mu_2$ and $\sigma_2^2$ anymore. This situation is represented by the  \Cref{estim4_rh0_n901_tp19} where the dispersion of the estimators $\hat \mu_2$ and $\hat \sigma_2^2$ are much bigger than the other parameters. 
%
%
%\begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu1_cas4.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma21_cas4.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu2_cas4.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma22_cas4.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_rho_cas4.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_corr_cas4.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0.5$, $r=0.7$, $n=11$, $n_j=2$, $k=4$}
%\label{estim_cas4}
%\end{figure}
% 
% 
%
%\begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu1_cas4n200.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma21_cas4n200.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_mu2_cas4n200.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_sigma22_cas4n200.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_rho_cas4n200.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim_corr_cas4n200.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0.5$, $r=0.7$, $n=101$, $n_j=2$, $k=49$}
%\label{estim_cas4n200}
%\end{figure}
% 
%
%
%\begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_mu1_n11_corr0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_sigma21_n11_r0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_mu2_n11_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_sigma22_n11_r0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_rho_n11_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_corr_n11_r0.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0.5$, $r=0$, $n=11$, $n_j=2$, $k=4$}
%\label{estim_cas4_r0_n11}
%\end{figure}
% 
% 
% \begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_mu1_n101_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_sigma21_n101_r0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_mu2_n101_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_sigma22_n101_r0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_rho_n101_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_corr0_n101.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0.5$, $r=0$, $n=101$, $n_j=2$, $k=49$}
%\label{estim_cas4_r0_n101}
%\end{figure}
% 
%  \begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_mu1_n501_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_sigma21_n501_r0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_mu2_n501_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_sigma22_n501_r0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_rho_n501_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_corr0_n501.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0.5$, $r=0$, $n=501$, $n_j=2$, $k=249$}
%\label{estim_cas4_r0_n501}
%\end{figure}
% 
% 
%\begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_mu1_n901_tp19_r0.png} \\
%\includegraphics[width=6.1 cm, height= 5 cm]{figures/estim0/estim4_sigma21_n901_tp19_r0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_mu2_n901_tp19_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_sigma22_n901_tp19_r0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_rho_n901_tp19_r0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_corr_n901_tp19_r0.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0.5$, $r=0$, $n=901$, $n_j=18$, $k=49$}
%\label{estim4_r0_n901_tp19}
%\end{figure} 
% 
% 
% \begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_mu1_n901_tp19.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_sigma21_n901_tp19.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_mu2_n901_tp19.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_sigma22_n901_tp19.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_rho_n901_tp19.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_corr_n901_tp19.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0.5$, $r=0.7$, $n=901$, $n_j=18$, $k=49$}
%\label{estim4_r07_n901_tp19}
%\end{figure}
%
% \begin{figure}[h!]
%\begin{multicols}{3}
%\centering
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_mu1_n901_rho0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_sigma21_n901_rho0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_mu2_n901_rho0.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_sigma22_n901_rho0.png}\\ 
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_rho0_n901.png} \\
%\includegraphics[width=6 cm, height= 5 cm]{figures/estim0/estim4_corr_n901_rho0.png} 
%\end{multicols}
%\caption{5000 simulated trajectories, $\mu_1=4$, $\mu_2=3$, $\sigma_1^2=5$, $\sigma_2^2=3$, $\rho=0$, $r=0.7$, $n=901$, $n_j=18$, $k=49$}
%\label{estim4_rh0_n901_tp19}
%\end{figure}



\clearpage

\begin{appendices}
\section{model's description}
\label{app:desc}

%\noindent $\Sigma$ is positive definite iff $| c_{ab}|\leq \sigma_a\sigma_b $.\\
%Let $P(\lambda)$ be the characteristic polynomial of the matrix $\Sigma - \lambda I_2$ so that
%\begin{align*}
%P(\lambda)&=det(\Sigma - \lambda I_2)\\
%&=\lambda^2-\lambda (\sigma_a^2+2 \sigma_b^2+2c_{ab})+\sigma_a^2\sigma_b^2-c_{ab}^2
%\end{align*}
%Thus, the roots of the polynomial $P$ are : $\lambda_1=\frac{\sigma_a^2+2\sigma_b^2+2c_{ab}-\sqrt{\Delta}}{2}$ and $\lambda_2=\frac{\sigma_a^2+2\sigma_b^2+2c_{ab}+\sqrt{\Delta}}{2}$ where $\Delta=(\sigma_a^2+2\sigma_b^2+2c_{ab})^2-4[(\sigma^2_a\sigma_b^2)-c_{ab}^2]$\\

%\noindent Then, $\lambda_1 \geq 0 \Leftrightarrow c_{ab}  \leq |\sigma_a\sigma_b|$
\section{Statistical Inference}
\subsection{$1^{st}$ observation scheme}
\label{app:inf1}

\end{appendices}









 
\bibliography{references2} 
 
 
\end{document}